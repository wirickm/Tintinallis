{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420a7e8-4c52-42fd-bd2a-0420ffccfba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9873a287-0f0f-487f-a8c6-8cb3b8289bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import plotly.graph_objects as go\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# imports for langchain and Chroma and plotly\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9977edf0-79df-465b-8560-454da448af4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL = \"gpt-4o-mini\"\n",
    "db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99fc184a-858e-4b9a-b85c-ce98d4e9e63a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API Key loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# In[14]:\n",
    "# Load environment variables from the specified .env file\n",
    "env_path = 'C:/Users/MichaelJWirickJr/keys.env'  # Update this path if necessary\n",
    "load_dotenv(env_path)\n",
    "\n",
    "# Set the OpenAI API key\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check if the API key is loaded correctly (optional for debugging)\n",
    "if openai.api_key:\n",
    "    print(\"‚úÖ OpenAI API Key loaded successfully.\")\n",
    "else:\n",
    "    print(\"‚ùå Error: OpenAI API Key not found. Please check your .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d98ce0d-9bcd-4849-be65-577504736de8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Input File: C:/Users/MichaelJWirickJr/Tintinallis_Emergency_Medicine/Section 1_summaries.md\n",
      "‚úÖ Loaded 1 document(s) from C:/Users/MichaelJWirickJr/Tintinallis_Emergency_Medicine/Section 1_summaries.md.\n",
      "‚úÖ Split document into 46 chunks.\n"
     ]
    }
   ],
   "source": [
    "# In[16]:\n",
    "# Path to the specific Markdown file\n",
    "\n",
    "#= r'C:/Users/MichaelJWirickJr/Tintinallis_Emergency_Medicine/Section 1.md'  # Update this path if necessary\n",
    "input_file_path = r'C:/Users/MichaelJWirickJr/Tintinallis_Emergency_Medicine/Section 1_summaries.md'  # Output summary file\n",
    "\n",
    "print(f\"üìÑ Input File: {input_file_path}\")\n",
    "#print(f\"üìÑ Output Summary File: {output_file_path}\")\n",
    "\n",
    "# In[17]:\n",
    "#from langchain.document_loaders import TextLoader\n",
    "#from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Load the specific Markdown document using LangChain's TextLoader\n",
    "loader = TextLoader(input_file_path, autodetect_encoding=True)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(documents)} document(s) from {input_file_path}.\")\n",
    "\n",
    "# Split the document into chunks using LangChain's CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"‚úÖ Split document into {len(chunks)} chunks.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a9b003d-ff39-40fe-a766-045127c5a37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f46fc86c-1f31-46c8-8030-d1ab977a97d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46ebcee2-9665-4ab0-8c5f-47b1f91290c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorstore created with 46 documents\n"
     ]
    }
   ],
   "source": [
    "# Create our Chroma vectorstore!\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5d75aaa-8196-4426-b483-3dd8e759d9c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors have 1,536 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Get one vector and find how many dimensions it has\n",
    "\n",
    "collection = vectorstore._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69af1654-8c3b-473f-add9-4d1fe4a283ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prework\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "#doc_types = [metadata['doc_type'] for metadata in result['metadatas']]\n",
    "#colors = [['blue', 'green', 'red', 'orange'][['products', 'employees', 'contracts', 'company'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ab0e7d-fec2-406e-b39c-7010aa1d3293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract the doc_type from metadata\n",
    "doc_types = [metadata.get('doc_type', 'Section 1: Resuscitative Problems and Techniques\\\n",
    " Advanced Airway Support') for metadata in result['metadatas']]\n",
    "\n",
    "print(f\"‚úÖ Extracted doc_types for {len(doc_types)} chunks.\")\n",
    "doc_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19437d3f-0545-43ca-8d6d-0e5b969a2586",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique doc_types found: ['Section 1: Resuscitative Problems and Techniques Advanced Airway Support']\n"
     ]
    }
   ],
   "source": [
    "# In[19]:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Identify unique document types\n",
    "unique_doc_types = sorted(set(doc_types))\n",
    "print(f\"Unique doc_types found: {unique_doc_types}\")\n",
    "\n",
    "# Define a color palette\n",
    "# Using a predefined color palette from matplotlib\n",
    "color_palette = plt.get_cmap('tab20')  # 'tab20' has 20 distinct colors\n",
    "\n",
    "# Create a mapping from doc_type to color\n",
    "color_map = {doc_type: color_palette(i) for i, doc_type in enumerate(unique_doc_types)}\n",
    "\n",
    "# Assign colors to each chunk based on its doc_type\n",
    "colors = [color_map[doc_type] for doc_type in doc_types]\n",
    "\n",
    "# For Plotly, colors need to be in hexadecimal or numeric format\n",
    "# Convert RGBA to hexadecimal\n",
    "def rgba_to_hex(rgba):\n",
    "    return f'rgba({int(rgba[0]*255)}, {int(rgba[1]*255)}, {int(rgba[2]*255)}, {rgba[3]})'\n",
    "\n",
    "colors_hex = [rgba_to_hex(color) for color in colors]\n",
    "\n",
    "# Perform t-SNE to reduce dimensionality to 3D\n",
    "#tsne = TSNE(n_components=3, random_state=42)\n",
    "#reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Define color mapping based on doc_types\n",
    "unique_doc_types = sorted(set(doc_types))\n",
    "color_palette = plt.get_cmap('tab20')\n",
    "color_map = {doc_type: color_palette(i) for i, doc_type in enumerate(unique_doc_types)}\n",
    "\n",
    "# Convert colors to hexadecimal for Plotly\n",
    "colors_hex = [f'rgba({int(color[0]*255)}, {int(color[1]*255)}, {int(color[2]*255)}, {color[3]})' for color in \n",
    "              [color_map[doc_type] for doc_type in doc_types]]\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31741379-2d63-41fa-815a-02dc8a76ae29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a function to display the 3D graph\n",
    "def display_3d_graph():\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=reduced_vectors[:, 0],\n",
    "        y=reduced_vectors[:, 1],\n",
    "        z=reduced_vectors[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=colors_hex,  # Use the hexadecimal colors from your color mapping\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "        hoverinfo='text'\n",
    "    )])\n",
    "    fig.update_layout(\n",
    "        title='3D Chroma Vector Store Visualization',\n",
    "        scene=dict(\n",
    "            xaxis_title='Dimension 1',\n",
    "            yaxis_title='Dimension 2',\n",
    "            zaxis_title='Dimension 3'\n",
    "        ),\n",
    "        width=800,\n",
    "        height=600,\n",
    "        margin=dict(r=20, b=10, l=10, t=40)\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fa2d7b46-633d-47fa-bbca-cc53d6402078",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique doc_types found: ['Section 1: Resuscitative Problems and Techniques Advanced Airway Support']\n"
     ]
    }
   ],
   "source": [
    "# In[19]:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# Identify unique document types\n",
    "unique_doc_types = sorted(set(doc_types))\n",
    "print(f\"Unique doc_types found: {unique_doc_types}\")\n",
    "\n",
    "# Define a color palette\n",
    "# Using a predefined color palette from matplotlib\n",
    "color_palette = plt.get_cmap('tab20')  # 'tab20' has 20 distinct colors\n",
    "\n",
    "# Create a mapping from doc_type to color\n",
    "color_map = {doc_type: color_palette(i) for i, doc_type in enumerate(unique_doc_types)}\n",
    "\n",
    "# Assign colors to each chunk based on its doc_type\n",
    "colors = [color_map[doc_type] for doc_type in doc_types]\n",
    "\n",
    "# For Plotly, colors need to be in hexadecimal or numeric format\n",
    "# Convert RGBA to hexadecimal\n",
    "def rgba_to_hex(rgba):\n",
    "    return f'rgba({int(rgba[0]*255)}, {int(rgba[1]*255)}, {int(rgba[2]*255)}, {rgba[3]})'\n",
    "\n",
    "colors_hex = [rgba_to_hex(color) for color in colors]\n",
    "\n",
    "# Initialize reduced_vectors as a global variable\n",
    "reduced_vectors = None\n",
    "\n",
    "def compute_reduced_vectors():\n",
    "    global reduced_vectors\n",
    "    # Reduce the dimensionality of the vectors using t-SNE\n",
    "    tsne = TSNE(n_components=3, random_state=42)\n",
    "    reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Compute reduced vectors before defining the display function\n",
    "compute_reduced_vectors()\n",
    "\n",
    "# Define a function to display the 3D graph\n",
    "def display_3d_graph():\n",
    "    fig = go.Figure(data=[go.Scatter3d(\n",
    "        x=reduced_vectors[:, 0],\n",
    "        y=reduced_vectors[:, 1],\n",
    "        z=reduced_vectors[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=5,\n",
    "            color=colors_hex,  # Use the hexadecimal colors from your color mapping\n",
    "            opacity=0.8\n",
    "        ),\n",
    "        text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "        hoverinfo='text'\n",
    "    )])\n",
    "    fig.update_layout(\n",
    "        title='3D Chroma Vector Store Visualization',\n",
    "        scene=dict(\n",
    "            xaxis_title='Dimension 1',\n",
    "            yaxis_title='Dimension 2',\n",
    "            zaxis_title='Dimension 3'\n",
    "        )\n",
    "    )\n",
    "    return fig\n",
    "    \n",
    "# Define a function to save conversation to CSV\n",
    "def save_to_csv(query, response):\n",
    "    filename = 'conversation_history.csv'\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "    # Create file with headers if it doesn't exist\n",
    "    if not os.path.exists(filename):\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Timestamp', 'Query', 'Response'])\n",
    "\n",
    "    # Append the new conversation\n",
    "    with open(filename, 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([timestamp, query, response])\n",
    "\n",
    "# Define a function to handle Q&A via RAG\n",
    "def answer_query(query):\n",
    "    # Ensure `query` is a single string\n",
    "    query = str(query)\n",
    "\n",
    "    # Perform similarity search directly on the query text\n",
    "    search_results = vectorstore.similarity_search(query)\n",
    "\n",
    "    # Concatenate search results for context\n",
    "    context = \" \".join([doc.page_content for doc in search_results])\n",
    "\n",
    "    # Generate a response using ChatGPT with the retrieved context\n",
    "    chat = ChatOpenAI(model_name=MODEL)\n",
    "    response = chat.invoke(context + \"\\n\\nUser Query: \" + query)\n",
    "\n",
    "    # Save conversation to CSV\n",
    "    save_to_csv(query, response.content)\n",
    "\n",
    "    return response.content\n",
    "\n",
    "        # Define the Gradio interface\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"# 3D Chroma Vector Store Visualization with Chat Interface\")\n",
    "    \n",
    "    with gr.Tab(\"Chat\"):\n",
    "        query_input = gr.Textbox(label=\"Enter your question:\")\n",
    "        response_output = gr.Textbox(label=\"Response\", interactive=False)\n",
    "        query_button = gr.Button(\"Ask\")\n",
    "        query_button.click(fn=answer_query, inputs=query_input, outputs=response_output)\n",
    "\n",
    "    with gr.Tab(\"3D Graph\"):\n",
    "        gr.Plot(display_3d_graph)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9f8bd4ca-da60-4ecf-8ad4-e2d9fdc8b8ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rerunning server... use `close()` to stop if you need to change `launch()` parameters.\n",
      "----\n",
      "* Running on public URL: https://14fd2b2167e4d6b62f.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://14fd2b2167e4d6b62f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd374199-e6f3-4f42-98a2-b504b4581148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7873\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "30e6db1f-f8c1-4ee6-871a-525eee43eb39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'save_to_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msave_to_csv\u001b[49m(query, response)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'save_to_csv' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c604c42-67a0-4e8e-87fe-525760bc3426",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
